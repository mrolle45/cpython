from __future__ import annotations

import os.path
import token
from typing import IO, Any, Dict, List, Optional, Sequence, Set, Text, Tuple, Type, Iterable
from dataclasses import dataclass, field, replace
from abc import abstractmethod
import re
import textwrap

from pegen.grammar import (
    Alt,
    Arg,
    Args,
    Cut,
    Forced,
    Gather0,
    Gather1,
    Grammar,
    GrammarVisitor,
    Group,
    Lookahead,
    Item,
    VarItem,
    NameLeaf,
    NegativeLookahead,
    NoType,
    Opt,
    PositiveLookahead,
    Repeat0,
    Repeat1,
    Rhs,
    Rule,
    StringLeaf,
    TypedName,
)

from pegen import parse_recipe
from pegen.parser import Parser, ParseResult, Token
from pegen.parser_generator import *


class InvalidNodeVisitor(GrammarVisitor):
    def visit_NameLeaf(self, node: NameLeaf) -> bool:
        name = node.value
        return str(name).startswith("invalid")

    def visit_StringLeaf(self, node: StringLeaf) -> bool:
        return False

    def visit_VarItem(self, node: VarItem) -> bool:
        return self.visit(node.item)

    def visit_Rhs(self, node: Rhs) -> bool:
        return any(self.visit(alt) for alt in node)

    def visit_Alt(self, node: Alt) -> bool:
        return any(self.visit(item) for item in node.items())

    def lookahead_call_helper(self, node: Lookahead) -> bool:
        return self.visit(node.node)

    def visit_PositiveLookahead(self, node: PositiveLookahead) -> bool:
        return self.lookahead_call_helper(node)

    def visit_NegativeLookahead(self, node: NegativeLookahead) -> bool:
        return self.lookahead_call_helper(node)

    def visit_Opt(self, node: Opt) -> bool:
        return self.visit(node.elem)

    def visit_Repeat0(self, node: Repeat0) -> Tuple[str, str]:
        return self.visit(node.elem)

    def visit_Repeat1(self, node: Repeat1) -> Tuple[str, str]:
        return self.visit(node.elem)

    def visit_Gather(self, node: Gather) -> Tuple[str, str]:
        return self.visit(node.elem)

    def visit_Group(self, node: Group) -> bool:
        return self.visit(node.rhs)

    def visit_Cut(self, node: Cut) -> bool:
        return False

    def visit_Forced(self, node: Forced) -> bool:
        return self.visit(node.node)


class _Traits(TargetLanguageTraits):

    language: ClassVar[str] = 'python'

    def default_header(self) -> str:
        return textwrap.dedent("""\
            #!/usr/bin/env python3.8
            # @generated by pegen from {filename}

            from __future__ import annotations

            import ast
            import sys
            import tokenize

            from typing import Any, Optional, Callable, cast

            from pegen.parser import (
                memoize, memoize_left_rec, logger, Parser, ParseResult
                )

            """
        )

    def default_trailer(self) -> str:
        cls_name = self.grammar.metas.get("class", "GeneratedParser")
        return textwrap.dedent(f"""

            if __name__ == '__main__':
                from pegen.parser import simple_parser_main
                simple_parser_main({cls_name})
            """
        )

    def comment_leader(self) -> str:
        return '# '

    def default_type(self, type: str = None) -> Code:
         return type or Code('Any')

    def null_type(self) -> Code:
        return Code('None')

    def default_value(self) -> str:
        return 'None'

    def empty_params(self, params: str = None) -> str:
        return ''

    def typed_name(self, name: TypedName) -> str:
        #p: str = str(name)
        #base_type = str(name.type.base) or self.default_type()
        #if name.callable:
        #    # This node is a callable type.
        #    subtypes = [param.typed_name() for param in name.type.params]
        #    p += f": Callable[[{', '.join(subtypes)}], {base_type}]"
        #else:
        #    p += f"{name}: {self.gen_type(name.type)}"
        #else:
        #    if name: parts.append(str(name))
        #p = ' '.join(parts)
        type = name.type and self.gen_type(name.type)
        if type:
            return f"{name.name}: {type}"
        else:
            return f"{name.name}"

    def gen_type(self, typ: Type) -> str:
        # A base type of NoCode suppresses the type name.
        if typ.val_type == NoCode():
            base_type = ''
        else:
            base_type = str(typ.val_type) or self.default_type()
        if typ.callable:
            # This node is a callable type.
            subtypes = [self.gen_type(param.type) for param in typ.params]
            return f"Callable[[{', '.join(subtypes)}], {base_type}]"
        else:
            return f"{base_type}"

    def parser_param(self) -> TypedName:
        return TypedName('_p', Code('Parser'))

    def parse_result_ptr_arg(self, assigned_name: ObjName = None) -> Arg:
        return

    def return_param(self, type: str = None) -> TypedName:
        if not type: type = self.default_type()
        return TypedName('_ppRes', Code(f'{self.default_type(type)}'))

    def inline_params(self, type: str = None) -> Params:
        return None

    def cast(self, value: str, type: TypedName) -> str:
        return f"cast({type.typed_name()}, {value})"

    def cut_value(self, value: str = None) -> str:
        return 'cut_sentinel'

    def bool_value(self, value: bool) -> str:
        return f"{bool(value)}"

    def bool_type(self) -> str: return Code('bool')

    def circular_type(self) -> Code: return Code('Circ')

    def str_value(self, value: bool) -> str:
        return value.replace('"', r'\"')

    def uniq_name(self, node: GrammarTree, assigned_name: str = None) -> str:
        """ A name which is unique among all objects in scope.
        The scope for a python file is the immediate parent, thus is all sibs.
        """
        return assigned_name or node.name

    def parse_result_ptr_param(self, assigned_name: str = None) -> Param:
        name = assigned_name and f"&_ptr_{assigned_name}" or "_ppRes"
        return Param(TypedName(name, Code('ParseResultPtr *')))

    def parse_func_params(self, name: TypedName = None) -> Params: ...

    def recipe_result(self, stmt: str, recipe: ParseRecipe) -> str:
        """ The last line of the recipe generated code. """
        if recipe.func_type.returns_status:
            stmt = f"return {stmt}"
        if recipe.comment:
            stmt = f"{stmt}   {self.comment(recipe.comment)}"
        return stmt

    def rule_func_name(self, rule: Rule) -> ObjName:
        return rule.name

    def rule_recipe(self, rule: Rule, src: ParseRecipeSource) -> ParseRecipe:
        """ Create a recipe for a Rule. """
        return ParseRecipeExternal(
            rule, rule.name, src,
            '_rhs',
            params=rule.type.params,
            func_type=ParseRule,
            extra=lambda: self.gen_rule(rule),
            inlines = [rule.rhs],
            typ=rule.type,
            use_inline=False,           # Call as parser method.
            )

    def sequence_recipe_args(self, seq: Seq, *seq_args: Args) -> Args:
        """ Actual arguments for a Seq parse function.
        seq_args varies with the type of sequence.  It's an initial subset of:
            * repeat1
            * sep
        """
        return Args([
            Arg(inline=seq.elem),
            *seq_args,
            ])

    def parse_value_expr(
            self, name: ObjName, args: Args, params: Params, *,
            func_type: Type[FuncBase] = None,
            assigned_name: ObjName = None,
        ) -> str:
        """ An expression which produces the desired parse result. """
        if func_type and func_type.use_parser and not func_type.nested:
            name = f"self.{name}"
        return f"{name}{args}"

    def gen_start(self, alt: Alt) -> None:
        """ Generate code to set starting line and col variables if required by action """
        if not alt.action or 'LOCATIONS' not in alt.action:
            return
        self.print("tok: Token = self._tokenizer.peek()")
        self.print("start_lineno, start_col_offset = tok.start")

    def action(self, alt: Alt) -> str:
        return self.Action(alt.action, Type(self.default_type(), Params()))

    def default_action(self, alt: Alt) -> Self.Action:
        expr: str
        type: str
        vars = alt.all_vars()
        if len(vars) > 1:
            expr = f"_PyPegen_dummy_name(_p, {', '.join(var.name.string for var in vars)})"
            type = Type("list", Params())
        else:
            if len(vars):
                cast = ""
                expr = f"{cast}{vars[0].name}"
                type = ProxyType(vars)
                #type = vars[0].return_type
            else:
                expr = f"{self.default_value()}"
                type = ObjType(self.default_type)
        return self.Action(expr, type)

    def dummy_action(self) -> _Traits.Action:
        return self.Action("dummy name", "str")

    def alt_action(self, node: Alt) -> Self.Action:
        """ String to be generated in a return statement in the Alt. """
        action = node.action
        if not action:
            if not node.items:
                action = "True"
            elif self.invalidvisitor.visit(node):
                action = "UNREACHABLE"
            else:
                names = [str(var.assigned_name) for var in node.all_vars()]
                if len(names) == 1:
                    action = names[0]
                else:
                    action = f"[{', '.join(names)}]"
        elif "LOCATIONS" in action:
            # The start location variables have already been set by self.gen_start()
            self.print("tok = self._tokenizer.get_last_non_whitespace_token()")
            self.print("end_lineno, end_col_offset = tok.end")
            action = action.replace("LOCATIONS", self.location_formatting)

        if "UNREACHABLE" in action:
            action = action.replace("UNREACHABLE", self.unreachable_formatting)

        return action

    def forward_declare_inlines(self, recipe: ParseRecipe) -> None:
        pass

    def gen_copy_local_vars(self, node: GrammarTree) -> None:
        """ Code to define inherited names and set their values stored in the parser. """
        return

    def enter_function(
        self, name: TypedName,
        func_type: ParseFuncType = ParseFunc,
        comment: str = '',
        ) -> Iterator:
        return self.enter_scope(
            self.decl_func(name, func_type=func_type),
            comment=comment
            )

    def decl_func(
        self, func: TypedName,
        func_type: ParseFuncType = ParseFunc, **kwds
        ) -> str:
        """ The declaration of a callable name (without the value), as a function.
        The variable is a function (not a function pointer), including function parameters.
        """
        assert func.callable, f"{func} must be callable."
        #assert func.type and func.type.params and func.name
        type = str(func.val_type)
        if func_type.has_result:
            type = f"ParseResult[{type}]"
        name = func.name
        params = func.type.params
        if func_type.use_parser and not func_type.nested:
            params = Params([Param(TypedName(ObjName('self'), None)), *params])
        return f"def {name}({ObjName(params.in_func())}) -> {type}:"

    def fix_parse_recipe(self, recipe: ParseRecipe) -> None:
        recipe.expr_name = recipe.src.name or recipe.name
        if recipe.node.assigned_name:
            func_name = f"_item_{recipe.node.assigned_name}"
        else:
            func_name = str(recipe.node.name)
        recipe.func_name = TypedName(
            func_name,
            recipe.outer_call.type,
            )

    def parse_recipe(self, recipe: ParseRecipe, **kwds) -> None:
        """ Generate inline code now. """
        if recipe.node.alt is recipe.node:
            self.print()
            self.print(comment=str(recipe.node))
        if type(recipe.node.parent) is VarItem:
            return
        recipe(**kwds)


class PythonParserGenerator(ParserGenerator, _Traits, GrammarVisitor):
    def __init__(
        self,
        grammar: Grammar,
        file: Optional[IO[Text]],
        *,
        tokens: Dict[int, str] = token.tok_name,
        exact_tokens: Dict[str, int] = token.EXACT_TOKEN_TYPES,
        location_formatting: Optional[str] = None,
        unreachable_formatting: Optional[str] = None,
        verbose: bool = False,
        skip_actions: bool = False,
    ):
        if not grammar: return
        self.skip_actions = skip_actions
        super().__init__(grammar, tokens, exact_tokens, set(), file)
        # The Python generator doesn't have a choice of Tokens file, like the C generator has.
        # It always uses Parser/Tokens, and this is incorporated into the tokens module when the library is built.
        self.exact_tokens = exact_tokens
        self.non_exact_tokens = set(tokens) - set(exact_tokens)
        self.token_types = {name: type for type, name in token.tok_name.items()}
        self.invalidvisitor: InvalidNodeVisitor = InvalidNodeVisitor()
        self.unreachable_formatting = unreachable_formatting or "None  # pragma: no cover"
        self.location_formatting = (
            location_formatting
            or "lineno=start_lineno, col_offset=start_col_offset, "
            "end_lineno=end_lineno, end_col_offset=end_col_offset"
        )

    def generate(self, filename: str) -> None:
        with self.gen_header_and_trailer(filename):
            super().generate(filename)

            self.collect_keywords(self.rules)
            self.print(comment="Keywords and soft keywords are listed at the end of the parser definition.")
            cls_name = self.grammar.metas.get("class", "GeneratedParser")
            self.print(f"class {cls_name}(Parser):")
            with self.indent():
                for rule in dict(self.rules).values():
                    self.print()
                    self.print(comment=str(rule))
                    if rule.left_recursive:
                        if rule.leader:
                            self.print(comment="Left-recursive leader")
                            self.print("@memoize_left_rec")
                        else:
                            # Non-leader rules in a cycle are not memoized,
                            # but they must still be logged.
                            self.print(comment="Left-recursive")
                            self.print("@logger")
                    elif rule.memo:
                        self.print("@memoize")
                    elif self.verbose:
                        self.print("@logger")
                    self.gen_node(rule)
                    #self.visit(rule)

                self.print()
                self.print(f"KEYWORDS = {tuple(self.keywords)}")
                self.print(f"SOFT_KEYWORDS = {tuple(sorted(self.soft_keywords))}")

    def gen_rule(self, rule: Rule) -> None:
        """ Generate extra code inside a Rule parse function. """
        return

    def gen_alt(
        self, alt: Alt, **kwds
        ) -> str:
        # Generate a function for each item, using the corresponding variable name
        fail_value = self.default_value()
        for item in alt.items():
            self.print()
            self.print(comment=f"{item}")
            self.gen_alt_item(item, fail_value)

        self.print()
        self.print(comment="parse succeeded")

        action = f"return {self.alt_action(alt)},"
        return action


    def gen_alt_item(self, item: VarItem, fail_value: str = None) -> None:
        """ Code which parses a single named item in an alt.
        Exits the alt if the parse fails.
            It is up to the caller of the alt to reset the mark.
        Otherwise assigns the result to a variable.
        """

        assert isinstance (item, VarItem)

        name = item.assigned_name

        item_type = item.parse_recipe.outer_call.type
        var_type = item_type.val_type
        rawname = f"_result_{name}"
        rawtype = f"ParseResult[{var_type}]"
        fail_value = fail_value or self.default_value()
        item.parse_recipe.gen_parse()
        parse_name = item.parse_recipe.func_name.name
        if item.parse_recipe.outer_call.func_type.always_true:
            if item.parse_recipe.outer_call.func_type.has_result:
                self.print(f"{name}: {var_type}")
                self.print(f"{name}, = {parse_name}()")
            else:
                self.print(f"{parse_name}()")
        elif not item.parse_recipe.outer_call.func_type.has_result:
            self.print(f"if not {parse_name}(): return {fail_value}")

        else:
            self.print(f"{name}: {var_type}; {rawname}: {rawtype}")
            self.print(f"{rawname} = {parse_name}()")
            self.print(f"if not {rawname}: return {fail_value}")
            self.print(f"{name}, = {rawname}")

    def alts_uses_locations(self, alts: Sequence[Alt]) -> bool:
        for alt in alts:
            if alt.action and "LOCATIONS" in alt.action:
                return True
            for n in alt.items:
                if isinstance(n.item, Group):
                    if self.alts_uses_locations(n.item.rhs): return True
        return False

    def rule_params(self, rule: Rule) -> str:
        """ The text for parameters to declare a rule. """
        params = ''.join([f', {param.name}: {self.param_type(param)}' for param in (rule.params)])
        return f"self{params}"

    def param_type(self, param: TypedName) -> str:
        """ What is generated for the type of a parameter, following '{param.name}:'
        The name may have its own parameters, which are generated recursively.
        """
        base_type = param.type or "Any"
        if param.params and len(param.params):
            # This node is a callable type.
            subtypes = [str(self.param_type(subparam)) for subparam in param.params]
            return f'Callable[[{", ".join(subtypes)}], {base_type}]'
        else:
            return base_type


    def gen_rhs_descriptors(self, rhs: Rhs, alt_names: List[str]) -> Tuple[str, Callable[[], None]]:
        """ Generate code to parse the individual alts and create descriptor(s) for them.
        Return the name of the descriptor(s) variable and the function to generate the code.
        """
        def gen() -> None:
            # Make descriptor table.
            self.print()
            with self.enter_scope(f"_alts =", '[]'):
                for name, alt in zip(alt_names, rhs):
                    self.print(f'{name},')

        descr_name = '_alts'
        return descr_name, gen

    # Descriptions of helper parsing functions...

    @functools.cached_property
    def parse_rule(self) -> ParseSource:
        return self.make_parser_name(
        '_rule', 'Any',
        ('rule', 'RuleDescr'),
        func_type=ParseFunc,
        )
    @functools.cached_property
    def parse_rule_memo(self) -> ParseSource:
        return self.make_parser_name(
        '_rule', 'Any',
        ('rule', 'RuleDescr'),
        func_type=ParseFunc,
        )
    @functools.cached_property
    def parse_rule_recursive(self) -> ParseSource:
        return self.make_parser_name(
        '_rule', 'Any',
        ('rule', 'RuleDescr'),
        func_type=ParseFunc,
        )
    @functools.cached_property
    def parse_alt(self) -> ParseSource:
        return self.make_parser_name(
        '_alts', 'Any',
        ('alts', 'List[RuleAltDescr]'),
        )
    @functools.cached_property
    def parse_alts(self) -> ParseSource:
        return self.make_parser_name(
        '_alts', 'Any',
        ('alts', 'List[RuleAltDescr]'),
        )
    @functools.cached_property
    def parse_NAME(self) -> ParseSource:
        return self.make_parser_name(
        '_name', 'Token'
        )
    @functools.cached_property
    def parse_NUMBER(self) -> ParseSource:
        return self.make_parser_name(
        '_number', 'Token'
        )
    @functools.cached_property
    def parse_STRING(self) -> ParseSource:
        return self.make_parser_name(
        '_string', 'Token'
        )
    @functools.cached_property
    def parse_OP(self) -> ParseSource:
        return self.make_parser_name(
        '_op', 'Token'
        )
    @functools.cached_property
    def parse_TYPE_COMMENT(self) -> ParseSource:
        return self.make_parser_name(
        '_type_comment', 'Token'
        )
    @functools.cached_property
    def parse_SOFT_KEYWORD(self) -> ParseSource:
        return self.make_parser_name(
        '_soft_keyword', 'Token'
        )
    @functools.cached_property
    def parse_token(self) -> ParseSource:
        return self.make_parser_name(
        '_expect_type', 'Token', ('type', 'int')
        )
    @functools.cached_property
    def parse_char(self) -> ParseSource:
        return self.make_parser_name(
        '_expect_char', 'Token', ('c', 'str')
        )
    @functools.cached_property
    def parse_forced(self) -> ParseSource:
        return self.make_parser_name(
        '_expect_forced', 'Any',
        ('result', 'Any'),
        ('expected', 'str'),
        func_type=parse_recipe.ParseTrue,
        )
    @functools.cached_property
    def parse_soft_keyword(self) -> ParseSource:
        return self.make_parser_name(
        '_expect_name', 'Token', ('name', 'str')
        )
    def parse_repeat(self, elem: ParseExpr) -> ParseSource:
        return self.make_parser_name(
            '_repeat', f'list[{elem.return_type}]',
            ('item', 'Callable[[], ParseResult]'),
            ('repeat1', 'int'),
        )
    def parse_gather(self, elem: ParseExpr) -> ParseSource:
        return self.make_parser_name(
            '_gather', f'list[{elem.return_type}]',
            ('item', 'Callable[[], ParseResult]'),
            ('sep', 'Callable[[], ParseResult]'),
            ('repeat1', 'int'),
        )
    def parse_opt(self, elem: ParseExpr) -> ParseSource:
        return self.make_parser_name(
            '_opt', f'list[{elem.return_type}]',
            ('item', 'Callable[[], ParseResult]'),
        )
    @functools.cached_property
    def parse_group(self) -> ParseSource:
        return self.make_parser_name(
            '_rhs', 'Any',
            ('rhs', 'Callable[[], ParseResult]'),
        )
    @functools.cached_property
    def parse_lookahead(self) -> ParseSource:
        return self.make_parser_name(
            '_lookahead', 'ParseStatus',
            ('positive', 'bool'),
            ('atom', 'Callable[[], ParseResult]'),
        )
    @functools.cached_property
    def parse_cut(self) -> ParseSource:
        return self.make_parser_name(
            '_cut', 'None',
            func_type=parse_recipe.ParseVoid,
        )

from pegen.parse_recipe import (
    ParseRecipe,
    ParseRecipeExternal,
    ParseRecipeLocal,
    ParseRecipeRule,
    ParseRecipeInline,
    ParseSource,
    ParseFuncType,
    ParseFunc,
    ParseTest,
    ParseTrue,
    ParseData,
    ParseNone,
    )

