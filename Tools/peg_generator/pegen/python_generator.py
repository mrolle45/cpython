from __future__ import annotations

import os.path
import token
from typing import IO, Any, Dict, List, Optional, Sequence, Set, Text, Tuple, Type, Iterable
from dataclasses import dataclass, field, replace
from abc import abstractmethod
import re
import textwrap

from pegen.grammar import (
    Alt,
    Arg,
    Args,
    Cut,
    Forced,
    Gather0,
    Gather1,
    Grammar,
    GrammarVisitor,
    Group,
    Lookahead,
    Item,
    VarItem,
    NameLeaf,
    NegativeLookahead,
    Opt,
    PositiveLookahead,
    Repeat0,
    Repeat1,
    Rhs,
    Rule,
    StringLeaf,
    TypedName,
)

from pegen import parse_recipe
from pegen.parser import Parser, ParseResult, Token
from pegen.parser_generator import *


class InvalidNodeVisitor(GrammarVisitor):
    def visit_NameLeaf(self, node: NameLeaf) -> bool:
        name = node.value
        return str(name).startswith("invalid")

    def visit_StringLeaf(self, node: StringLeaf) -> bool:
        return False

    def visit_VarItem(self, node: VarItem) -> bool:
        return self.visit(node.item)

    def visit_Rhs(self, node: Rhs) -> bool:
        return any(self.visit(alt) for alt in node)

    def visit_Alt(self, node: Alt) -> bool:
        return any(self.visit(item) for item in node.items())

    def lookahead_call_helper(self, node: Lookahead) -> bool:
        return self.visit(node.node)

    def visit_PositiveLookahead(self, node: PositiveLookahead) -> bool:
        return self.lookahead_call_helper(node)

    def visit_NegativeLookahead(self, node: NegativeLookahead) -> bool:
        return self.lookahead_call_helper(node)

    def visit_Opt(self, node: Opt) -> bool:
        return self.visit(node.elem)

    def visit_Repeat0(self, node: Repeat0) -> Tuple[str, str]:
        return self.visit(node.elem)

    def visit_Repeat1(self, node: Repeat1) -> Tuple[str, str]:
        return self.visit(node.elem)

    def visit_Gather(self, node: Gather) -> Tuple[str, str]:
        return self.visit(node.elem)

    def visit_Group(self, node: Group) -> bool:
        return self.visit(node.rhs)

    def visit_Cut(self, node: Cut) -> bool:
        return False

    def visit_Forced(self, node: Forced) -> bool:
        return self.visit(node.node)


class _Traits(TargetLanguageTraits):

    language: ClassVar[str] = 'python'

    def default_header(self) -> str:
        return textwrap.dedent("""\
            #!/usr/bin/env python3.8
            # @generated by pegen from {filename}

            from __future__ import annotations

            import ast
            import sys
            import tokenize

            from typing import Any, Optional, Callable, cast

            from pegen.parser import (
                memoize, memoize_left_rec, logger, Parser, ParseResult, RuleDescr, RuleAltDescr, cut_sentinel
                )

            """
        )

    def default_trailer(self) -> str:
        cls_name = self.grammar.metas.get("class", "GeneratedParser")
        return textwrap.dedent(f"""

            if __name__ == '__main__':
                from pegen.parser import simple_parser_main
                simple_parser_main({cls_name})
            """
        )

    def comment_leader(self) -> str:
        return '# '

    def default_type(self, type: str = None) -> Code:
        return type or Code('Any')

    def default_value(self) -> str:
        return 'None'

    def default_params(self, params: str = None) -> str:
        return ''

    def parser_param(self) -> TypedName:
        return TypedName('_p', Code('Parser'))

    def return_param(self, type: str = None) -> TypedName:
        if not type: type = self.default_type()
        return TypedName('_ppRes', Code(f'{self.default_type(type)}'))

    def inline_params(self, type: str = None) -> Params:
        return None

    def cast(self, value: str, type: TypedName) -> str:
        return f"cast({type.typed_name()}, {value})"

    def cut_value(self, value: str = None) -> str:
        return 'cut_sentinel'

    def bool_value(self, value: bool) -> str:
        return f"{bool(value)}"

    def bool_type(self) -> str: return Code('bool')

    def str_value(self, value: bool) -> str:
        return value.replace('"', r'\"')

    def parse_result_ptr_param(self, assigned_name: str = None) -> Param:
        name = assigned_name and f"&_ptr_{assigned_name}" or "_ppRes"
        return Param(TypedName(name, Code('ParseResultPtr *')))

    def parse_func_params(self, name: TypedName = None) -> Params: ...

    def rule_func_name(self, rule: Rule) -> ObjName: ...

    def rule_recipe(self, rule: Rule, src: ParseRecipeSource) -> ParseRecipe:
        """ Create a recipe for a Rule. """
        return ParseRecipeExternal(
            rule, rule.name, src,
            # Add an argument for the rule descriptor.
            '_rule_descriptor',
            func_type=ParseFunc,
            extra=lambda: self.gen_rule(rule),
            inlines = [rule.rhs],
            value_type=rule.type,
            )

    def sequence_recipe_args(self, seq: Seq, *seq_args: Args) -> Args:
        """ Actual arguments for a Seq parse function.
        seq_args varies with the type of sequence.  It's an initial subset of:
            * repeat1
            * sep
        """
        return Args([
            Arg(inline=seq.elem),
            *seq_args,
            ])

    def default_func_type(self) -> ParseFunc:
        return ParseFunc

    def parse_value_expr(self, name: ObjName, args: Args, func_type: Type[FuncBase] = None):
        """ An expression which produces the desired parse result. """
        if func_type and func_type.use_parser:
            name = f"self.{name}"
        return f"{name}{args}"

    def gen_start(self, alt: Alt) -> None:
        """ Generate code to set starting line and col variables if required by action """
        if not alt.action or 'LOCATIONS' not in alt.action:
            return
        self.print("tok: Token = self._tokenizer.peek()")
        self.print("start_lineno, start_col_offset = tok.start")

    def gen_action(self, node: Alt) -> str:
        """ String to be generated in a return statement in the Alt. """
        action = node.action
        if not action:
            if not node.items:
                action = "True"
            elif self.invalidvisitor.visit(node):
                action = "UNREACHABLE"
            else:
                names = [str(var.assigned_name) for var in node.all_vars()]
                if len(names) == 1:
                    action = names[0]
                else:
                    action = f"[{', '.join(names)}]"
        elif "LOCATIONS" in action:
            # The start location variables have already been set by self.gen_start()
            self.print("tok = self._tokenizer.get_last_non_whitespace_token()")
            self.print("end_lineno, end_col_offset = tok.end")
            action = action.replace("LOCATIONS", self.location_formatting)

        if "UNREACHABLE" in action:
            action = action.replace("UNREACHABLE", self.unreachable_formatting)

        return action

    def forward_declare_inlines(self, recipe: ParseRecipe) -> None:
        pass

    def gen_copy_local_vars(self, node: GrammarTree) -> None:
        """ Code to define inherited names and set their values stored in the parser. """
        return

    def enter_function(
            self, name: TypedName,
            func_type: ParseFunc,
            comment: str = ''
        ) -> Iterator:
        return self.enter_scope(
            self.decl_func(name, func_type),
            comment=comment
            )

    def decl_func(self, func: TypedName, func_type: ParseFunc) -> str:
        """ The declaration of a callable name (without the value), as a function.
        The variable is a function (not a function pointer), including function parameters.
        """
        assert func.params and func.name
        type = str(func.type)
        if func_type.has_result:
            type = f"ParseResult[{type}]"
        name = func.name
        params = func.params
        if func_type.use_parser:
            params = Params([Param(TypedName('self', Code(''))), *params])
        return f"def {name}({ObjName(params.in_func())}) -> {type}:"

    def fix_parse_recipe(self, recipe: ParseRecipe) -> None:
        recipe.expr_name = recipe.src.name or recipe.name
        if recipe.outer_call.assigned_name:
            func_name = f"_item_{recipe.outer_call.assigned_name}"
        else:
            func_name = str(recipe.name)
        #if not isinstance(recipe.node, Rule):
        #    func_name = f"_item_{func_name}"
        #if recipe.src.use_parser:
        #    # The src is a method of the parser.
        #    recipe.src.name = 'self.' + recipe.src.name
        recipe.func_name = TypedName(
            func_name,
            recipe.outer_call.type,
            recipe.params)
        recipe.outer_call.name = ObjName(func_name)

    def parse_recipe(self, recipe: ParseRecipe, **kwds) -> None:
        """ Generate inline code now. """
        if type(recipe.node.parent) is VarItem:
            return
        recipe(self, **kwds)


class PythonParserGenerator(ParserGenerator, _Traits, GrammarVisitor):
    def __init__(
        self,
        grammar: Grammar,
        file: Optional[IO[Text]],
        *,
        tokens: Dict[int, str] = token.tok_name,
        exact_tokens: Dict[str, int] = token.EXACT_TOKEN_TYPES,
        location_formatting: Optional[str] = None,
        unreachable_formatting: Optional[str] = None,
        verbose: bool = False,
    ):
        super().__init__(grammar, tokens, exact_tokens, set(), file)
        # The Python generator doesn't have a choice of Tokens file, like the C generator has.
        # It always uses Parser/Tokens, and this is incorporated into the tokens module when the library is built.
        self.exact_tokens = exact_tokens
        self.non_exact_tokens = set(tokens) - set(exact_tokens)
        self.token_types = {name: type for type, name in token.tok_name.items()}
        self.invalidvisitor: InvalidNodeVisitor = InvalidNodeVisitor()
        self.unreachable_formatting = unreachable_formatting or "None  # pragma: no cover"
        self.location_formatting = (
            location_formatting
            or "lineno=start_lineno, col_offset=start_col_offset, "
            "end_lineno=end_lineno, end_col_offset=end_col_offset"
        )

    def generate(self, filename: str) -> None:
        with self.gen_header_and_trailer(filename):
            super().generate(filename)

            self.collect_keywords(self.rules)
            self.print(comment="Keywords and soft keywords are listed at the end of the parser definition.")
            cls_name = self.grammar.metas.get("class", "GeneratedParser")
            self.print(f"class {cls_name}(Parser):")
            with self.indent():
                for rule in dict(self.rules).values():
                    self.print()
                    self.print(comment=str(rule))
                    if rule.left_recursive:
                        if rule.leader:
                            self.print(comment="Left-recursive leader")
                            self.print("@memoize_left_rec")
                        else:
                            # Non-leader rules in a cycle are not memoized,
                            # but they must still be logged.
                            self.print(comment="Left-recursive")
                            self.print("@logger")
                    elif rule.memo or self.verbose:
                        self.print("@memoize")
                    self.gen_node(rule)
                    #self.visit(rule)

                self.print()
                self.print(f"KEYWORDS = {tuple(self.keywords)}")
                self.print(f"SOFT_KEYWORDS = {tuple(self.soft_keywords)}")

    def gen_rule(self, rule: Rule) -> None:
        """ Generate extra code inside a Rule parse function. """
        # Make a rule descriptor.
        self.print(f"_rule_descriptor = RuleDescr(_rhs, {str(rule.name)!r}, {str(rule.rhs)!r})")
        return

    #def gen_alt(self, rule: Rule) -> None:
    #    return

    def gen_alt(
        self, alt: Alt, **kwds
    ) -> str:
        def gen():
            # Generate a function for each item, using the corresponding variable name
            fail_value = self.default_value()
            for item in alt.items():
                self.print()
                self.print(comment=f"{item}")
                # If the item is a Cut, then there's no item name, but there's a Cut function
                if isinstance(item.item, Cut):
                    fail_value = self.cut_value()
                    continue
        
                self.gen_alt_item(item, fail_value)

            self.print()
            self.print(comment="parse succeeded")

            action = f"return {self.gen_action(alt)},"
            return action

        return gen()

    def gen_alt_item(self, item: VarItem, fail_value: str = None) -> None:
        """ Code which parses a single named item in an alt.
        Exits the alt if the parse fails.
            It is up to the caller of the alt to reset the mark.
        Otherwise assigns the result to a variable.
        """

        assert isinstance (item, VarItem)

        name = item.assigned_name

        item_type = item.parse_recipe.outer_call.type
        var_type = item_type
        rawname = f"_result_{name}"
        rawtype = f"ParseResult[{item_type}]"
        fail_value = fail_value or self.default_value()
        self.gen_parse(item.parse_recipe)
        parse_name = item.parse_recipe.outer_call.name
        if item.parse_recipe.outer_call.func_type.always_true:
            self.print(f"{name}: {var_type}")
            self.print(f"{name}, = {parse_name}()")
        elif not item.parse_recipe.outer_call.func_type.has_result:
            self.print(f"if not {parse_name}(): return {fail_value}")

        else:
            self.print(f"{name}: {var_type}; {rawname}: {rawtype}")
            self.print(f"{rawname} = {parse_name}()")
            self.print(f"if not {rawname}: return {fail_value}")
            self.print(f"{name}, = {rawname}")

    def alts_uses_locations(self, alts: Sequence[Alt]) -> bool:
        for alt in alts:
            if alt.action and "LOCATIONS" in alt.action:
                return True
            for n in alt.items:
                if isinstance(n.item, Group):
                    if self.alts_uses_locations(n.item.rhs): return True
        return False

    def rule_params(self, rule: Rule) -> str:
        """ The text for parameters to declare a rule. """
        params = ''.join([f', {param.name}: {self.param_type(param)}' for param in (rule.params)])
        return f"self{params}"

    def param_type(self, param: TypedName) -> str:
        """ What is generated for the type of a parameter, following '{param.name}:'
        The name may have its own parameters, which are generated recursively.
        """
        base_type = param.type or "Any"
        if param.params and len(param.params):
            # This node is a callable type.
            subtypes = [str(self.param_type(subparam)) for subparam in param.params]
            return f'Callable[[{", ".join(subtypes)}], {base_type}]'
        else:
            return base_type

    def visit_Rule(self, node: Rule) -> None:

        rhs = node.flatten()
        if node.left_recursive:
            if node.leader:
                self.print("@memoize_left_rec")
            else:
                # Non-leader rules in a cycle are not memoized,
                # but they must still be logged.
                self.print("@logger")
        elif node.memo or self.verbose:
            self.print("@memoize")
        node_type = node.type or "Any"
        self.print(comment=f"{node.name}: {rhs}")
        with self.enter_function(TypedName(node.name, Code(f"ParseResult[{node_type}]"), self.rule_params(node))):
            self.visit(rhs, ctx=InlFuncCtx('_rhs'))
            #self.gen_rhs(rhs)
            self.print('return _rhs()')

    #def visit_Rhs(self, node: Rhs,
    #    ctx: FuncCtx,
    #    **kwds) -> FuncInfo:
    #    """ Generate function definition for the Rhs.
    #    Used only within a Group.
    #    """
    #    self.print(f"def {ctx.name('_rhs')}():")
    #    with self.indent():
    #        self.gen_rhs(node)

    #    return ctx.func_info('_rhs', 'Any')

    #def gen_rhs(self, node: Rhs) -> None:

    #    def gen_alt(alt: Alt, suffix: int = 0) -> str:
    #        name = f"_alt{f'_{suffix}' if suffix else ''}"
    #        # The body of the alternative, returns (result,) or None.
    #        self.visit(alt, ctx=InlFuncCtx(name))
    #        return name

    #    alts = node
    #    if len(alts) == 1:
    #        gen_alt(alts[0])
    #        self.print("return self._alt(_alt)")
    #    else:
    #        names = []
    #        for n, alt in enumerate(node, 1):
    #            names.append(gen_alt(alt, n))
    #        self.print(f"return self._alts({', '.join(names)})")

    def gen_rhs_descriptors(self, rhs: Rhs, alt_names: List[str]) -> Tuple[str, Callable[[], None]]:
        """ Generate code to parse the individual alts and create descriptor(s) for them.
        Return the name of the descriptor(s) variable and the function to generate the code.
        """
        def gen() -> None:
            # Make descriptor table.
            self.print()
            with self.enter_scope(f"_alt_descriptors =", '[]'):
                for name, alt in zip(alt_names, rhs):
                    self.print(f'RuleAltDescr({name}, {name!r}, {str(alt)!r}),')

        descr_name = '_alt_descriptors'
        return descr_name, gen

    # Older version
    #def gen_parse(self, recipe: ParseRecipe,
    #    **kwds
    #    ) -> None:

    #    node: GrammarNode = recipe.src
    #    dflt_name: str = recipe.dflt_name
    #    function: TypedName = TypedName(recipe.name, recipe.src.type)
    #    args: Args = recipe.args
    #    extra: Callable[[], None] = recipe.extra
    #    assert isinstance(args, Args)
    #    call = recipe.value_expr()
    #    comment: str = recipe.comment
    #    self.forward_declare_inlines(recipe)
    #    inlines = {arg.name: arg.inline for arg in recipe.args if arg.inline}
    #    if args is not None:
    #        call = f"{call}{args}"
    #    return_type = self.default_type(function.type)

    #    with self.enter_function(TypedName(recipe.func_name, return_type, self.default_params())):
    #        for inline in recipe.inline_recipes():
    #            # Expand the inline items.
    #            self.visit(inline.node)
    #        if comment:
    #            call = f"{call}   # {comment}"
    #        if extra:
    #            extra()
    #        self.print(f"return {call}")

    # Newer version, copied from c_generator.
    def gen_parse(self, recipe: ParseRecipe,
        **kwds
        ) -> None:
        self.forward_declare_inlines(recipe)
        #lead = recipe.node.depth() * '    '
        #print(f"{lead}{recipe.node!r}")
        #print(f"{lead}{recipe.mode.name} {recipe.func_name}")

        return_type = recipe.src.type
        if isinstance(recipe.node, Rule):
            return_type = recipe.node.type
        if recipe.mode is not recipe.Loc or 0x00001:
            #if recipe.node is not recipe.alt:
            #    self.print(comment=str(recipe.node))
            with self.enter_function(
                recipe.func_name,
                recipe.func_type,
                ):
                for inline in recipe.inline_recipes():
                    # Expand the inline items.
                    self.gen_node(inline.node)
                self.gen_copy_local_vars(recipe.node)
                #if recipe.mode is recipe.Rule:
                #    self.gen_return_var(TypedName('_result'))
                call: str | None = None
                if recipe.extra:
                    call = recipe.extra()
                if call is None:
                    # Was not supplied by extra()
                    call = recipe.value_expr()
                    call = f"return {call}"
                    if recipe.comment:
                        call = f"{call}   {self.comment(recipe.comment)}"
                if call: self.print(call)

    # Descriptions of helper parsing functions...

    @functools.cached_property
    def parse_rule(self) -> TypedName:
        return self.make_parser_name(
        '_rule', 'Any',
        ('rule', 'RuleDescr'),
        func_type=ParseFunc,
        )
    @functools.cached_property
    def parse_rule_memo(self) -> TypedName:
        return self.make_parser_name(
        '_rule', 'Any',
        ('rule', 'RuleDescr'),
        func_type=ParseFunc,
        )
    @functools.cached_property
    def parse_rule_recursive(self) -> TypedName:
        return self.make_parser_name(
        '_rule', 'Any',
        ('rule', 'RuleDescr'),
        func_type=ParseFunc,
        )
    @functools.cached_property
    def parse_alt(self) -> TypedName:
        return self.make_parser_name(
        '_alts', 'Any',
        ('alts', 'List[RuleAltDescr]'),
        )
    @functools.cached_property
    def parse_alts(self) -> TypedName:
        return self.make_parser_name(
        '_alts', 'Any',
        ('alts', 'List[RuleAltDescr]'),
        )
    @functools.cached_property
    def parse_NAME(self) -> TypedName:
        return self.make_parser_name(
        '_name', 'Token'
        )
    @functools.cached_property
    def parse_NUMBER(self) -> TypedName:
        return self.make_parser_name(
        '_number', 'Token'
        )
    @functools.cached_property
    def parse_STRING(self) -> TypedName:
        return self.make_parser_name(
        '_string', 'Token'
        )
    @functools.cached_property
    def parse_OP(self) -> TypedName:
        return self.make_parser_name(
        '_op', 'Token'
        )
    @functools.cached_property
    def parse_TYPE_COMMENT(self) -> TypedName:
        return self.make_parser_name(
        '_type_comment', 'Token'
        )
    @functools.cached_property
    def parse_SOFT_KEYWORD(self) -> TypedName:
        return self.make_parser_name(
        '_soft_keyword', 'Token'
        )
    @functools.cached_property
    def parse_token(self) -> TypedName:
        return self.make_parser_name(
        '_expect_type', 'Token', ('type', 'int')
        )
    @functools.cached_property
    def parse_char(self) -> TypedName:
        return self.make_parser_name(
        '_expect_char', 'Token', ('c', 'str')
        )
    @functools.cached_property
    def parse_forced(self) -> TypedName:
        return self.make_parser_name(
        '_expect_forced', 'Any',
        ('result', 'Any'),
        ('expected', 'str'),
        )
    @functools.cached_property
    def parse_soft_keyword(self) -> TypedName:
        return self.make_parser_name(
        '_expect_name', 'Token', ('name', 'str')
        )
    def parse_repeat(self, elem: ParseExpr) -> TypedName:
        return self.make_parser_name(
            '_repeat', f'list[{elem.parse_recipe.outer_call.type}]',
            ('item', 'Callable[[], ParseResult]'),
            ('repeat1', 'int'),
        )
    def parse_gather(self, elem: ParseExpr) -> TypedName:
        return self.make_parser_name(
            '_gather', f'list[{elem.parse_recipe.outer_call.type}]',
            ('item', 'Callable[[], ParseResult]'),
            ('sep', 'Callable[[], ParseResult]'),
            ('repeat1', 'int'),
        )
    def parse_opt(self, elem: ParseExpr) -> TypedName:
        return self.make_parser_name(
            '_opt', f'list[{elem.parse_recipe.outer_call.type}]',
            ('item', 'Callable[[], ParseResult]'),
        )
    @functools.cached_property
    def parse_group(self) -> TypedName:
        return self.make_parser_name(
            '_rhs', 'Any',
            ('rhs', 'Callable[[], ParseResult]'),
        )
    @functools.cached_property
    def parse_lookahead(self) -> TypedName:
        return self.make_parser_name(
            '_lookahead', 'ParseStatus',
            ('positive', 'bool'),
            ('atom', 'Callable[[], ParseResult]'),
        )
    @functools.cached_property
    def parse_cut(self) -> TypedName:
        return self.make_parser_name(
            '_cut', None,
            func_type=parse_recipe.ParseVoid,
        )

from pegen.parse_recipe import (
    ParseRecipe,
    ParseRecipeExternal,
    ParseRecipeLocal,
    ParseRecipeRule,
    ParseRecipeInline,
    ParseSource,
    ParseFuncType,
    ParseFunc,
    ParseTest,
    ParseTrue,
    ParseData,
    ParseLocal,
    ParseNone,
    )

